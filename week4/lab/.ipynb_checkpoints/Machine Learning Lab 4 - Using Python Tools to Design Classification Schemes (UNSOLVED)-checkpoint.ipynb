{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning: Lab 4 - Using Python to Design Classification Systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welcome to the final lab of the Machine Learning course at CoderSchool! Your final project is to build a *Spotify Music Recommendation System*. \n",
    "\n",
    "In order to do this, you will have to focus on having a good **DESIGN** for your system.\n",
    "\n",
    "A good design means knowing a few things:\n",
    "* Which Classifiers to use\n",
    "* How to Connect them together\n",
    "* How to produce a final \"Score\"\n",
    "\n",
    "You spent the first half of today's lab trying to draw out a design and think of ways to produce your score from your classifiers.\n",
    "\n",
    "Now, we will look at a few Python functions that can help you achieve your design. You don't *have* to use any of these objects; the final project can be completed without using these concepts. But knowing that they exist gives you some more options and you could find them helpful!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataSet\n",
    "\n",
    "We'll use a consolidated dataset of `Dance`, `Jazz`, `Rock`, and `Rap` from Assignment 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 770,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "\n",
    "# # Ignore warnings\n",
    "# import warnings\n",
    "# warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 771,
   "metadata": {},
   "outputs": [],
   "source": [
    "# songs_dataset = pd.read_csv('Consolidated_DF_6000.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# songs_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a 10% split to use for our training and testing. We'll work with `genres` first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 773,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = songs_dataset.drop('genres', axis=1)\n",
    "# y = songs_dataset['genres']\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Pipeline` object in Python is a way to simply connect many different processes or steps together. Let's combine the `SelectKBest` step with a `RandomForestClassifier` step to see how we can use a `Pipeline`.\n",
    "\n",
    "First, from `sklearn.pipeline` import `Pipeline`. Then from `sklearn.feature_selection` import `SelectKBest`, and import `RandomForestClassifier` from `sklearn.ensemble`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, create a `RandomForestClassifier` called `rfc`, and a `SelectKBest` object called `selector`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing we need to do is tell the `Pipeline` all the different steps that will be involved.\n",
    "\n",
    "We can arrange steps in a list in the follinwg way:\n",
    "`steps = [(<name of step 1>, object 1), (<name of step 2>, object 2), etc.]`\n",
    "\n",
    "So for our example, we can use something like\n",
    "`steps = [('feature_selection', selector), ('random_forest', rfc)]`\n",
    "\n",
    "Try it out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, to make a `Pipeline`, simply pass the `steps` to our `Pipeline` object in the following way:<br>\n",
    "`pipeline = Pipeline(steps)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can call `.fit`, and `.predict` on our `pipeline` object just like any other model!\n",
    "\n",
    "Call `.fit`, `.predict`, and then print the `classification_report`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining GridSearchCV and Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cool thing about a `Pipeline` is that you can use a single `GridSearchCV` object to try different combinations for different values! \n",
    "\n",
    "from `sklearn.grid_search` import `GridSearchCV`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will try 2 values of `k` for `SelectKBest`, 2 values for `n_estimators` and 2 values for the `min_samples_split` for our `RandomForestClassifier`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to use the following syntax for defining the parameters:\n",
    "* `<name of step in pipeline> + '__' + <name of parameter>`.\n",
    "\n",
    "For example:\n",
    "* the name of our `SelectKBest` step in our pipeline is `feature_selection`\n",
    "* we want to change the `k` value\n",
    "* so the syntax is: `feature_selection__k`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 782,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters = dict(feature_selection__k=[5,10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modify `parameters` above to add the following values for the `RandomForestClassifier` step as well:<br>\n",
    " `n_estimators: [50, 100]\n",
    " min_samples_split: [2,10]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! Now you know how to use `GridSearchCV` -- call it on your `pipeline` object, passing in your new `parameters`. Set `verbose=3` so you can see it in action! Call `.fit` and `.predict` on your `GridSearchCV` object and print the `classification_report`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pickling\n",
    "\n",
    "'Pickling' is a way to save your python objects to disk. You can simply save ANY python variable to your computer as a `.pickle` file and later read it. It saves time and will help you when testing!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# some_model = [1, 2, 3, 4, 5, 6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print `some_model`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The way to save your object is to call `pickle.dump`. You pass in a filename with a `.pickle` extension (in this case, `my_model.pickle`). `wb` means we are in write mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 786,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle.dump(some_model, open('my_model.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check your computer! You should see a file called `my_model.pickle`.\n",
    "\n",
    "The way to load your object is to call `pickle.load`. You pass in the filename that you want to load. `rb` means we are in read mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some_model_2 = pickle.load(open('my_model.pickle', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print `some_model_2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cool! We successfully saved and loaded a python variable to disk.\n",
    "\n",
    "In our example, we used a list, but you can use almost any object -- a pandas DataFrame, a RandomForestClassifier model, a Doc2Vec model, a Bag Of Words matrix - almost **ANYTHING** !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Label Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A song can be *both* `happy` and `celebratory`. For this reason, `moods` is an example of a variable that can be described as `multi-label`. In your final project, you might choose to work with `moods` and hence with multi-label output. You can choose to do this in several ways. One way is to use one of Python's built-in classifiers which supports Multi-Label output directly! Egs: `RandomForestClassifier`, `KNeighborsClassifier`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataSet\n",
    "Remember how we saw that you can save anything use `.pickle`? Read in `songs_aggressive.pickle` and save it in `songs_aggressive`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the `type` of songs_aggressive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice it is a pandas DataFrame -- this means we saved a pandas dataframe as a pickle file. Nice! Print its `head`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to create a `train_test_split`. We want our features (`X`) to be our `audio_features` from `songs_aggressive`.<br>\n",
    "**Note:** A quick way to get your features into a list format for the `train_test_split` from the pandas Series format is to use `.values.tolist()`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want our labels, `y`,  to be the `moods` from `songs_aggressive`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should see that, for many entries, there are multiple labels. For example, for index `36359`, the label has 3 values: <br>`['angsty', 'aggressive', 'rowdy']`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now what we want to do is convert our labels into numbers. Remember, computers always work with numbers!!! We will do this using the `MultiLabelBinarizer`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from `sklearn.preprocessing` import `MultiLabelBinarizer`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a new instance of `MultiLabelBinarizer()` and save it in `mlb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now call `.fit_transform` on our labels above (`y`). Store it in `y_labels`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print y_labels to see what it looks like. It should look like a bunch of lists with 1s and 0s. Each list is a label that has been converted into numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print `mlb.classes_`, `y_labels[0]`, and `y.iloc[0]` and compare them. You will notice how the labels have been encoded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, because we are going to use a `KNeighborsClassifier`, we need to scale our features. Use a `StandardScaler` to scale `X`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to create our `train_test_split`! Use `test_size=0.1`, `random_state=42`, `X`, and `y_labels`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, create your `KNeighborsClassifier`, `.fit` it to the training data, call `.predict` and print the `classification_report`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier Chains\n",
    "\n",
    "Classifier Chains are a way to combine many multi-label classifiers together in a way such that each classifier in the chain gets the output of the previous classifier and uses it as a feature! This might be helpful if your labels are co-related. Moods are probably co-related, so let's see if it helps.\n",
    "\n",
    "Let's try it out on our current dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from `sklearn.multioutput` import `ClassifierChain`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`ClassifierChain` takes in as an argument the kind of classifier you want to use. Let's use `KNeighborsClassifier` so we can compare our results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can now `.fit` and `.predict` on your chain just like you would a normal classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What did you observe? Did your score improve?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that, the number of classifiers in the chain will be equal to the number of labels! You can check this by comparing `len(chain.estimators_)` and `len(mlb.classes_)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's also useful to know that the *order* of the classifiers inside the chain is important and can probably influence your results. Check the python [documentation](http://scikit-learn.org/stable/modules/generated/sklearn.multioutput.ClassifierChain.html) and [example](http://scikit-learn.org/stable/auto_examples/multioutput/plot_classifier_chain_yeast.html#sphx-glr-auto-examples-multioutput-plot-classifier-chain-yeast-py) for the parameters you can pass to your chain.\n",
    "\n",
    "For more info, you can also check out section 4.1.2 on Classifier Chains in this [article](https://www.analyticsvidhya.com/blog/2017/08/introduction-to-multi-label-classification/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Binary Classifiers and looking at Probabilities\n",
    "\n",
    "Another technique you can try is to instead use individual binary classifiers and look at the probability of their predictions. This can help you do things like declare the *top* 3 moods for example. You can also use the probabilities in the calculation of your similarity score, when deciding which songs are more similar than others to your test song.\n",
    "\n",
    "Let's take a quick look at how to inspect the probability for a prediction, using a `RandomForestClassifier` as an example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataSet\n",
    "\n",
    "We'll work with `genres` here, as in Assignment 1. Read in `Consolidated_Dance_Jazz.csv`, which contains all the audio features and the genres for `Dance` and `Jazz` songs. Store it in `songs_dance_jazz`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# songs_dance_jazz = pd.read_csv('Consolidated_Dance_Jazz.csv')\n",
    "# songs_dance_jazz.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform the following steps:\n",
    "* Build a `LogisticRegression` classifier called `logReg`.\n",
    "* Use all the audio features as features.\n",
    "    * Remember to scale your features!\n",
    "* Use `genres` as the labels.\n",
    "* Make a `train_test_split` with `test_size=0.33, random_state=42`. \n",
    "* `.fit`, `.predict`, and print the `classification_report` for `logReg`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should see an `f1-score` of around `0.95`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probabilities\n",
    "\n",
    "Let's look at the song at index 20 and see what the prediction probabilities were!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logReg.predict(X_test[20].reshape(1,-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see the classifier predicted the song at index 20 as `dance`. How confident was it? We use the `predict_proba` method to find out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should see that it was around `80.14 %` sure that it was a `dance` song, and `19.86 %` sure it was `jazz`\n",
    "\n",
    "To see the classes themselves, you can simply print `logReg.classes_`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Voting Classifiers\n",
    "\n",
    "Voting Classifiers are a convenient way to simply group many classifiers together, and take the result that most of them predict. Let's see this with a quick example using 3 classifiers: `KNearestNeighbors`, `SVC`, and `LogisticRegression`.\n",
    "\n",
    "Do the following:\n",
    "* Create a KNearestNeighbors Classifier\n",
    "* Create a SVC (Support Vector Machine Classifier)\n",
    "* Create a Logistic Regression Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, using the same `X_train` / `X_test` / `y_train` / `y_test` as before, fit all your classifiers to the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now: Let us look at the prediction each classifier has for the song at index `20`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 813,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dance']\n",
      "['jazz']\n",
      "['dance']\n"
     ]
    }
   ],
   "source": [
    "# song_index = 20\n",
    "# print(logReg.predict(X_test[song_index].reshape(1,-1))) # Logistic Regression prediction\n",
    "# print(knn.predict(X_test[song_index].reshape(1,-1))) # kNN prediction\n",
    "# print(svc.predict(X_test[song_index].reshape(1,-1))) # Support Vector Machine Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how `kNN` predicted the song as `jazz`, while the other 2 predicted the song as `dance`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we can do is create a `VotingClassifier` that has these 3 classifiers, and its output will automatically be the most popular prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from `sklearn.ensemble` import `VotingClassifier`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a `VotingClassifier` that contains all your above classifiers! It requires you pass in a `list` of your classifiers, each element in the list with the following syntax:\n",
    "\n",
    "`(<some name for your classifier>, <your classifier object>)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, `.fit` your `voting_classifier` on `X_train` and `y_train`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the prediction for song at index 20 !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice it is `dance`! This is because it was the majority vote from the previous 3 classifiers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cosine Similarity\n",
    "\n",
    "If you decide to use the **Million Song DataSet** *(MSD)*, you won't have any mood information (unless you try to use the *MSD* and `MasterSongList.json` together ;)). In this case, one very popular similarity metric is called *cosine similarity*. It basically decides that 2 vectors are similar if they are close together to each other. You can learn more about cosine similarity in this [picture](https://lh5.googleusercontent.com/lYq5EWtpgku57oUGff4oBcQWNaxmvj9IIXGF7_ILr9uA1wgvlI0_j8dYc00)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create 3 sentences that are similar. We'll make sentence_1 and sentence_2 more 'similar' to each other than sentence_3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentence_1 = \"Mason really loves food\"\n",
    "# sentence_2 = \"Hannah loves food too\"\n",
    "# sentence_3 = \"The pizza is food\"\n",
    "# all_sentences = [sentence_1, sentence_2, sentence_3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, now let's create a bag of words model using `CountVectorizer` and `.fit_transform` it to the above sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 819,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from `sklearn.metrics.pairwise` import `cosine_similarity`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how 'similar' sentence_1 and sentence_2 are. Remember that the feature vectors for these sentences live inside our `bag_of_words` !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You see a value of `0.5`, which means they are pretty similar!\n",
    "\n",
    "What about sentence_1 and sentence_3 ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see a value of `0.25`, which means they are not as similar.\n",
    "\n",
    "Remember, a value of `1` and the closer the value gets to `0` it means they are not the same. `-1` means they are the 'opposite' !\n",
    "\n",
    "OK, that's it for now. All the best with the final project!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommended Reading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Multi-Label Classification: Yelp Example**<br>\n",
    "http://mondego.ics.uci.edu/projects/yelp/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Python page on Multi-Label and Multi-Class Classification**<br>\n",
    "http://scikit-learn.org/stable/modules/multiclass.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GridSearchCV & Pipeline: Example**<br>\n",
    "https://www.civisanalytics.com/blog/workflows-in-python-using-pipeline-and-gridsearchcv-for-more-compact-and-comprehensive-code/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Classifier Chains**<br>\n",
    "https://www.analyticsvidhya.com/blog/2017/08/introduction-to-multi-label-classification/ (see section 4.1.2)<br>\n",
    "http://scikit-learn.org/stable/auto_examples/multioutput/plot_classifier_chain_yeast.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
